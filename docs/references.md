# References

- https://github.com/pgvector/pgvector-node#prisma
- https://github.com/langchain-ai/langchainjs/blob/54d9f92/langchain/src/vectorstores/prisma.ts#L130
- https://supabase.com/docs/guides/ai
- https://supabase.com/blog/hugging-face-supabase
- https://supabase.com/partners/integrations/prisma
- https://supabase.com/blog/openai-embeddings-postgres-vector
- https://github.com/withastro/astro/blob/main/packages/markdown/remark/package.json
- https://github.com/remarkjs/remark#example-support-for-gfm-and-frontmatter
- https://github.com/remarkjs/remark-frontmatter/blob/main/lib/index.js
- https://kuzudb.com/docusaurus/blog/llms-graphs-part-2/
- https://github.com/tiangolo/full-stack-fastapi-template

Small cross encoder
https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-4-v2

hybrid search using pgvector
https://github.com/pgvector/pgvector-python/blob/master/examples/hybrid_search_rrf.py
https://github.com/pgvector/pgvector-python/blob/master/examples/hybrid_search.py

track token usage using tiktoken
https://github.com/openai/tiktoken

reduce size of the docker for faster cold starts
https://github.com/GoogleContainerTools/distroless/blob/main/examples/python3/Dockerfile
https://www.uvicorn.org/deployment/

use models which use safetensors for faster load
https://huggingface.co/docs/diffusers/en/using-diffusers/using_safetensors
https://huggingface.co/tomaarsen/all-MiniLM-L6-v2
